{
  "$schema": "https://charm.land/crush.json",
  "providers": {
    "ollama": {
      "name": "Local Ollama",
      "base_url": "http://localhost:11434/v1/",
      "type": "openai",
      "api_key": "ollama",
      "models": [
        {
          "name": "ðŸ”§ Groq Tool Use 8B (BEST FOR TOOLS)",
          "id": "llama3-groq-tool-use:8b",
          "context_window": 8192,
          "default_max_tokens": 4096
        },
        {
          "name": "ðŸ”§ Llama 3.2 3B (fast+tools)",
          "id": "llama3.2:3b",
          "context_window": 131072,
          "default_max_tokens": 8192
        },
        {
          "name": "âš¡ DeepSeek Coder 6.7B",
          "id": "deepseek-coder:6.7b",
          "context_window": 16384,
          "default_max_tokens": 4096
        },
        {
          "name": "âš¡ Mistral 7B",
          "id": "mistral:7b",
          "context_window": 32768,
          "default_max_tokens": 8192
        }
      ]
    }
  },
  "mcp": {
    "filesystem": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home/mgilbert/Code"],
      "timeout": 120,
      "disabled": false
    },
    "searxng": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "@kevinwatt/mcp-server-searxng"],
      "timeout": 60,
      "disabled": false,
      "env": {
        "SEARXNG_URL": "http://localhost:8888"
      }
    },
    "github": {
      "type": "stdio",
      "command": "npx",
      "args": ["-y", "any-cli-mcp-server", "gh"],
      "timeout": 120,
      "disabled": false
    }
  }
}
